{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfCtx trainer + world tokenizer\n",
    "The trainer validation with the world otkenizer\n",
    "\n",
    "> This project assumes you have the rwkv-infctx conda env setup, and you are executing in that environment - see the main README.md for the conda env setup steps\n",
    ">\n",
    "> All training runs (except dryrun) is configured to log to weights and bias, comment out the logger in the config file if you want to avoid this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "## Setup & Tokenizer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets setup the various directories\n",
    "!mkdir -p ../../model/\n",
    "!mkdir -p ../../datapath/\n",
    "!mkdir -p ../../checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/ubuntu/.cache/huggingface/datasets/teven___parquet/teven--enwiki_10k-de63a925546e70ab/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 959.14it/s]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset\n",
    "!cd ../../RWKV-v4neo && python3 preload_datapath.py ../notebook/trainer-validation/config/baseline-dryrun-world.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer Code validation via dryrun\n",
    "\n",
    "The following dryrun, help do a basic check that the existing trainer code changes are valid across 2 * 2 data samples.\n",
    "\n",
    "If this check fail, its most probably a code / envrionment setup issue (no further checks needed)\n",
    "\n",
    "It does not log the run the W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 17:36:08,219] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.1.0.dev20230706'\n",
      "---- Initializing model ----\n",
      "No of layers: 6\n",
      "Embedding size: 512\n",
      "Output model path: ../model/L6-D512-world-init.pth\n",
      "Vocab size: 65529\n",
      "---- ----- ----\n",
      "Using /home/ubuntu/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py311_cu118/wkv_1_bf16/build.ninja...\n",
      "Building extension module wkv_1_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=wkv_1_bf16 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/include -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/include/TH -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -t 4 -std=c++17 -res-usage --maxrregcount 60 --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DTmax=1 -c /home/ubuntu/rwkv5x-tokenshift-exp-A/RWKV-v4neo/cuda/wkv_cuda_bf16.cu -o wkv_cuda_bf16.cuda.o \n",
      "ptxas info    : 1 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z15kernel_backwardiiiPKfPKN3c108BFloat16ES4_S4_S0_S4_S0_PS2_S5_S5_S5_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z15kernel_backwardiiiPKfPKN3c108BFloat16ES4_S4_S0_S4_S0_PS2_S5_S5_S5_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 48 registers, 464 bytes cmem[0]\n",
      "ptxas info    : Compiling entry function '_Z14kernel_forwardiiiPKfPKN3c108BFloat16ES4_S4_S0_PS2_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z14kernel_forwardiiiPKfPKN3c108BFloat16ES4_S4_S0_PS2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, 424 bytes cmem[0]\n",
      "[2/3] c++ -MMD -MF wkv_op_bf16.o.d -DTORCH_EXTENSION_NAME=wkv_1_bf16 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/include -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/include/TH -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/anaconda3/envs/rwkv-infctx/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -std=c++17 -O3 -DTmax=1 -c /home/ubuntu/rwkv5x-tokenshift-exp-A/RWKV-v4neo/cuda/wkv_op_bf16.cpp -o wkv_op_bf16.o \n",
      "[3/3] c++ wkv_op_bf16.o wkv_cuda_bf16.cuda.o -shared -L/home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o wkv_1_bf16.so\n",
      "Loading extension module wkv_1_bf16...\n",
      "[RWKV.model]: Finished initial model load\n",
      "65529 512   -0.0001 emb.weight\n",
      "512   512   0    blocks.0.att.key.weight\n",
      "512   512   1.0  blocks.0.att.value.weight\n",
      "512   512   0    blocks.0.att.receptance.weight\n",
      "512   512   0    blocks.0.att.output.weight\n",
      "2048  512   1.0  blocks.0.ffn.key.weight\n",
      "512   512   0    blocks.0.ffn.receptance.weight\n",
      "512   2048  0    blocks.0.ffn.value.weight\n",
      "512   512   0    blocks.1.att.key.weight\n",
      "512   512   1.0  blocks.1.att.value.weight\n",
      "512   512   0    blocks.1.att.receptance.weight\n",
      "512   512   0    blocks.1.att.output.weight\n",
      "2048  512   1.0  blocks.1.ffn.key.weight\n",
      "512   512   0    blocks.1.ffn.receptance.weight\n",
      "512   2048  0    blocks.1.ffn.value.weight\n",
      "512   512   0    blocks.2.att.key.weight\n",
      "512   512   1.0  blocks.2.att.value.weight\n",
      "512   512   0    blocks.2.att.receptance.weight\n",
      "512   512   0    blocks.2.att.output.weight\n",
      "2048  512   1.0  blocks.2.ffn.key.weight\n",
      "512   512   0    blocks.2.ffn.receptance.weight\n",
      "512   2048  0    blocks.2.ffn.value.weight\n",
      "512   512   0    blocks.3.att.key.weight\n",
      "512   512   1.0  blocks.3.att.value.weight\n",
      "512   512   0    blocks.3.att.receptance.weight\n",
      "512   512   0    blocks.3.att.output.weight\n",
      "2048  512   1.0  blocks.3.ffn.key.weight\n",
      "512   512   0    blocks.3.ffn.receptance.weight\n",
      "512   2048  0    blocks.3.ffn.value.weight\n",
      "512   512   0    blocks.4.att.key.weight\n",
      "512   512   1.0  blocks.4.att.value.weight\n",
      "512   512   0    blocks.4.att.receptance.weight\n",
      "512   512   0    blocks.4.att.output.weight\n",
      "2048  512   1.0  blocks.4.ffn.key.weight\n",
      "512   512   0    blocks.4.ffn.receptance.weight\n",
      "512   2048  0    blocks.4.ffn.value.weight\n",
      "512   512   0    blocks.5.att.key.weight\n",
      "512   512   1.0  blocks.5.att.value.weight\n",
      "512   512   0    blocks.5.att.receptance.weight\n",
      "512   512   0    blocks.5.att.output.weight\n",
      "2048  512   1.0  blocks.5.ffn.key.weight\n",
      "512   512   0    blocks.5.ffn.receptance.weight\n",
      "512   2048  0    blocks.5.ffn.value.weight\n",
      "65529 512   0.5  head.weight\n"
     ]
    }
   ],
   "source": [
    "# Lets initialized the L6-D512 model with the init_model.py code\n",
    "!cd ../../RWKV-v4neo/ && python3 init_model.py --n_layer 6 --n_embd 512 --vocab_size world ../model/L6-D512-world-init.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 17:56:47,385] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.1.0.dev20230706'\n",
      "/home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '../notebook/trainer-validation/config/baseline-dryrun-world.yaml'], args=['fit', '-c', '../notebook/trainer-validation/config/baseline-dryrun-world.yaml'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 3941088705\n",
      "[RWKV.model]: Preloading model from '../model/L6-D512-world-init.pth'\n",
      "Using /home/ubuntu/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py311_cu118/wkv_128_bf16/build.ninja...\n",
      "Building extension module wkv_128_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_128_bf16...\n",
      "[RWKV.model]: Loading model weights ( L6-D512-V65529 )\n",
      "[RWKV.model]: Finished initial model load\n",
      "/home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/fabric/connector.py:555: UserWarning: bf16 is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "Found cached dataset parquet (/home/ubuntu/.cache/huggingface/datasets/teven___parquet/teven--enwiki_10k-de63a925546e70ab/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 992.03it/s]\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/teven___parquet/teven--enwiki_10k-de63a925546e70ab/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-70540b7bc7714436_*_of_00032.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/teven___parquet/teven--enwiki_10k-de63a925546e70ab/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-1cc2969752440d36_*_of_00032.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/teven___parquet/teven--enwiki_10k-de63a925546e70ab/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-f28a37ee000f1a49_*_of_00032.arrow\n",
      "[rank: 0] Global seed set to 3941088705                                         \n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[2023-08-15 17:56:51,724] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "Enabling DeepSpeed BF16.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[RWKV.model][rank=0] Configuring optimizer ...\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  6.000e-04 (0.0006)\n",
      "    - lr_final: 4.000e-04 (0.0004)\n",
      "\n",
      "Using /home/ubuntu/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py311_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.341132640838623 seconds\n",
      "[RWKV.model][rank=0] Loaded optimizer (linear schedule) ...\n",
      "Rank: 0 partition count [1, 1, 1] and sizes[(87578624, False), (3072, False), (3072, False)] \n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 33.6 M\n",
      "1 | blocks | ModuleList | 20.5 M\n",
      "2 | ln_out | LayerNorm  | 1.0 K \n",
      "3 | head   | Linear     | 33.6 M\n",
      "--------------------------------------\n",
      "87.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.6 M    Total params\n",
      "350.339   Total estimated model params size (MB)\n",
      "Epoch 0:   0%|    | 1/5249 [00:06<8:46:02,  6.01s/it, v_num=0, train/loss=11.20]/home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1688627653114/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  overflow_gpu = get_accelerator().ByteTensor([overflow])\n",
      "Epoch 0:   0%|    | 4/5249 [00:09<3:21:40,  2.31s/it, v_num=0, train/loss=10.40]`Trainer.fit` stopped: `max_steps=2` reached.\n",
      "Epoch 0:   0%|    | 4/5249 [00:09<3:21:45,  2.31s/it, v_num=0, train/loss=10.40]\n"
     ]
    }
   ],
   "source": [
    "# Validate source code and env is working, by doing a short 2 sample dryrun\n",
    "!cd ../../RWKV-v4neo && python3 lightning_trainer.py fit -c ../notebook/trainer-validation/config/baseline-dryrun-world.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
